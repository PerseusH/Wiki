## Linux内存分配

- **kmalloc和vmalloc**分配的是**内核内存**, **malloc**分配的是**用户内存**

- kmalloc能分配的大小有限,vmalloc和malloc能分配的大小相对较大

- `kmalloc`是基于**slab分配器**来实现的，其分配的**物理内存是连续的**。vmalloc比kmalloc慢

  - **使用连续物理地址对Cache友好**，有利于提高性能

- 在**设备驱动或者内核模块**中动态开辟内存，不是用malloc，而是kmalloc ,vmalloc，或者用get_free_pages直接申请页。释放内存用的是kfree,vfree，或free_pages

- vmalloc区为**非连续内存分区**。vmalloc是一个接口函数, 内核代码使用它来分配在**虚拟内存中连续**但在物理内存中不一定连续的内存，**不能直接用于DMA**

- `vmalloc`这部分区域对应的线性地址在内核使用vmalloc分配内存时，其实就已经分配了相应的物理内存，并做了相应的映射，建立了相应的页表项，但相关页表项仅写入了内核页表，并没有实时更新到进程页表中，内核在这里使用了延迟更新的策略，将进程页表真正更新推迟到第一次访问相关线性地址，发生page fault时，在page fault的处理流程中进行进程页表的更新

- 使用vmalloc的最著名的实例是**内核模块**的实现. 因为模块可能在任何时候加载, 如果模块数据比较多, 那么无法保证有足够的连续内存可用, 特别是在系统已经运行了比较长时间的情况下。如果能够用小块内存拼接出足够的内存, 那么使用vmalloc可以规避该问题

## 内存碎片

1. 内部碎片是由于采用**固定大小的内存分区**，当一个进程不能完全使用分给它的固定内存区域时，就将该进程分配后剩余的部分称为内碎片。内部碎片就是**已经被分配**出去（能明确指出属于哪个进程）却**不能被利用**的内存空间
2. 外部碎片指的是还没有被分配出去（不属于任何进程），但由于**连续内存太小**，无法分配给申请内存空间的新进程的内存空闲区域

- 内存碎片与操作系统无关，因为操作系统提供的内存分配函数（如HeapAlloc）只能用来分配大块内存。小块内存只能靠用户级的内存分配器（如malloc）。产生内存碎片的罪魁祸首就是**堆内的小块内存的频繁分配**

  - 对于malloc等函数，每次申请完内存后都会释放，但每次释放的内存大小及释放时间的不同就会产生内存碎片。比如：在内存单元100的起始地址到内存单元200之间，共申请了100个1字节的空间。在free时，释放了内存地址为奇数的内存单元（如101,103,105……）而偶数单元不释放，释放了50个1字节空间，虽然总空间数为50字节，但由于这50个1字节空间不连续。当下次要申请2字节的内存单元时，却无法在100到200的内存地址单元中申请到空间，于是就产生内存碎片问题（**大量碎片引起无法malloc**）

- 对于64bit寻址，32gb内存远远小于其最大寻址范围，何况是计算量和存储量很大的服务器，现在大数据时代服务器硬盘都是tb级，早就有了海量数据在内存中的排序问题这类基本算法题，在内存可利用空间很低，碎片会极大影响系统效率

- 对nginx进行二次开发，做一些接口类服务。因为进程本身需要长时间不重启，同时由于访问量大，如果经过多次、长时间的累计，必然造成内存的上涨，导致服务出问题

  ##### 解决方案

  - 分页机制：相比较固定分配分区，内碎片问题已经明显减少
  - 分段机制：消除内碎片问题，但会产生外碎片问题
  - 借用**jemalloc、tcmalloc**来内存管理
  - 内存池，slab分配器，伙伴算法。最大slab大小如果过大，内存利用率会很低
  - 拥有先进**GC机制**的语言（如Java、C#），在对抗内存碎片方面表现较好。它们的GC一般会有个Compact步骤，会移动对象在内存中的位置，将多个对象整齐无间隙地排列好，从而消除了不少内存碎片
  - nginx自己开发的**内存池**，小块内存在一个访问结束后，这个访问的内存没被删除，直接就放回内存池了，而大块内存在一个访问结束后则会把大块内存删除返回给操作系统，这样做在很大程度上就避免了频繁产生内存碎片，导致大内存无法分配的问题
  - OS级别，给APP用**多级页表机制**来分配大内存块，当每个块的碎片过多时就会开辟新的块给APP用，旧块则回收
  - 对于分布式系统来说，部分**节点重启**不影响整体系统的运行。因此，整个系统看上去仿佛是多年不停机，实际上承载它们的节点服务器早已重启过很多次了