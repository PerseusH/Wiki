|内存分配 -> Go编译器默认在函数的栈帧（stack frame）中分配本地变量。'编译器会做逃逸分析'(escape analysis)，当发现变量的作用域超出函数范围('内存逃逸': 变量在函数结束返回后可能被引用，一般是函数返回指针)时，则编译器必须在存在垃圾回收的堆（garbage-collected heap）上分配变量以避免指针错误。小内存变量直接分配在栈，若内存不够则在堆分配；大内存变量直接在堆分配
    -> 比如C中不能，但Go中可以这么干
        type struct T { xxx}
        func f() *T {
            var ret T
            return &ret //内存逃逸
        }
        -> 因为变量ret在函数f()结束后有可能被其他对象引用，所以它的内存会在堆上分配，Go的编译器会决定在哪(堆or栈)分配内存，保证程序的正确性
    |逃逸分析的用处（为了性能）
        1.最大的好处是减少gc的压力，不逃逸的对象'分配在栈上'，当函数返回时就回收了资源，'不需要gc标记清除'
        2.逃逸分析完后可以确定哪些变量可以分配在栈上，栈的分配比堆快，性能好
        3.互斥锁消除，如果你定义的对象的方法上有互斥锁，却只有一个线程在访问，此时逃逸分析后的机器码会去掉互斥锁运行
    -> 程序汇编码中，runtime.newobject(x)表示变量的内存是在堆上分配的
    -> 即使对于动态new出来的局部变量，编译器也会根据'是否有逃逸行为'来决定是分配在堆还是栈，而不是直接分配在堆中
    -> 当栈增长或者收缩时，goroutine 中的栈内存会被一块新的内存替换
    -> 堆从低向高增长，栈从高向低增长

    |打印出栈的信息
        package main
        import (
            "fmt"
            "runtime"
        )
        func main() {
            fmt.Println(stack())
        }
        func stack() string {
            var buf [2 << 10]byte
            return string(buf[:runtime.Stack(buf[:], true)]) //打印栈信息
        }
        >>>
        qxcs-MacBook-Pro% go run test.go
        goroutine 1 [running]:
        main.stack(0x0, 0xc42003bf68)
                /Users/qxc/work/test/test.go:14 +0x5b
        main.main()
                /Users/qxc/work/test/test.go:9 +0x26

|垃圾回收 -> golang内置runtime，支持垃圾回收。变量的是否可回收只取决于该变量是否可达。遍历所有包级变量和当前函数的所有局部变量（因为函数内部的局部变量只有当函数正在执行的时候才开始生命周期），如果不存在到达变量的访问路径则表示变量不可达(堆上没有被指针索引的值)。GC清理的'目标是堆内存'
    -> GO语言编译之后生成的是'可执行文件'，不像Java生成的是字节码
    -> Java的字节码由Java虚拟机执行，垃圾回收当然就由虚拟机完成
    -> Go生成的是一个'本地可执行文件'，它包含了'垃圾回收'的代码，会自动开辟一个线程进行垃圾回收
    -> 不同Go可执行程序之间是'不共享垃圾回收模块'的，这样就使得Go程序之间存在冗余（不过多占一点地方也不是问题）
    -> Go1.8已经将Gc的最差情况优化到了100微妙左右，正常的服务gc一般都在10微妙

    |栈空间清理(自清理) -> 函数调用完成后，没有必要立即清理被调用函数的栈帧空间，这样做只会浪费时间，因为你不知道那块内存之后是否会被再次用到。所以相应内存就原封不动的留在那里。只有当发生了函数调用，这块'内存被再次用到时'，才会对它进行清理。清理过程是通过拷贝过来的值在这个栈帧中的初始化完成的，因为所有的变量至少会被初始化为相应类型的零值，这就保证了'发生函数调用时，栈空间一定会被合理的清理'

    |算法 -> Go1.3以前使用标记清除法(Mark-Sweep)，Go1.5使用三色标记算法，go 1.5 在源码中的解释是“非分代的、非移动的、并发的(垃圾回收和用户程序并发执行)、三色的标记清除垃圾收集器”
        -> '根对象'包括：全局变量，各个Goroutine stack上的变量等
        |三色标记算法 -> 白色: 待回收区; 灰色: 暂存区; 黑色: 保留区
            1.一开始把所有对象都标记为白色(图)
            2.栈扫描('开始时STW',从根结点'非递归地遍历'所有白色对象,包括全局指针和 goroutine栈上的指针,把和根节点连接的对象都放入灰色队列),做一些准备工作,比如 enable write barrier。然后取消STW,将扫描任务作为多个并发的goroutine入队给调度器,进而被CPU处理(栈扫描根对象是为了找出引用链,根对象即runtime已知的objects集合)
            3.遍历灰色对象,将灰色对象引用的白色对象放入灰色区,然后将已遍历的灰色对象放入黑色区。重复遍历直到没有灰色对象(灰色队列为空)
            4.通过write-barrier检测('再次STW')，若对象有变化，重复以上操作
            5.收集剩余白色对象(garbage)
            -> 因为go支持并行GC, GC的扫描和go代码可以同时运行, 这样带来的问题是GC扫描的过程中go代码有可能改变了对象的依赖树. 为了避免这个问题, go在GC的标记阶段会启用写屏障(Write Barrier)，当指针发生改变, GC会认为在这一轮的扫描中这个指针是存活的, 所以放入灰色队列
            -> 并发的三色标记算法是一个经典算法，通过write barrier，维护'黑色对象不能引用白色对象'这条约束，就可以'保证程序的正确性'。Go1.5会在标记(Mark)阶段开启write barrier。在这个阶段里，如果用户代码想要执行操作，修改一个黑色对象去'引用白色对象'，则write barrier代码直接'将该白色对象置为灰色'。去读源代码实现的时候，有一个很小的细节：原版的算法中只是黑色引用白色则需要将白色标记，而Go1.5实现中是不管黑色/灰色/白色对象，只要引用了白色对象，就将这个白色对象标记。这么做的原因是，Go的标记位图跟对象本身的内存是在不同的地方，无法原子性地进行修改，而采用一些线程同步的实现代价又较高，所以这里的算法做过一些变种的处理

        -> '没有分代收集算法'，所以遇到巨量的小对象还是很麻烦的，会导致整个 mark 过程十分长，在某些极端情况下，甚至会导致 GC 线程占据 50% 以上的 CPU
        -> go 除了标准的三色收集以外，还有一个辅助回收功能，防止垃圾产生过快手机不过来的情况。这部分代码在 runtime.gcAssistAlloc 中
        -> 应该尽量避免频繁创建'临时堆'对象(如&abc{},new,make等)以'减少垃圾收集时的扫描时间'，对于需要频繁使用的临时对象考虑直接通过数组缓存进行重用

        |GC触发
            1.阈值：默认内存扩大一倍，启动gc
            2.定期：默认2min触发一次gc，src/runtime/proc.go:forcegcperiod
            3.手动：runtime.gc()

        |STW问题(Stop The World) -> '标记清除法的缺陷'。因为算法在标记时必须暂停整个程序，否则其他线程的代码可能会改变对象状态，从而可能把不应该回收的对象当做垃圾收集掉。当程序中的对象逐渐增多时，递归遍历整个对象树会消耗很多的时间，在大型程序中这个时间可能会是毫秒级别的。让所有的用户等待几百毫秒的 GC 时间这是不能容忍的
            -> STW是gc的最大性能问题，对于gc而言，需要'停止所有的内存变化'，即停止所有的goroutine，等待gc结束之后才恢复
            -> Golang gc 优化的核心就是尽量使得 STW 的时间越来越短
            -> 目前整个GC流程会进行'两次STW', 第一次是Mark阶段的开始, 第二次是Mark Termination阶段
                -> 第一次STW会准备根对象的扫描, 启动写屏障(Write Barrier)和辅助GC
                -> 第二次STW会重新扫描部分根对象, 禁用写屏障(Write Barrier)和辅助GC
                -> 不是所有根对象的扫描都需要STW, 例如扫描栈上的对象只需要停止拥有该栈的Goroutine
                -> 从go1.9开始,写屏障使用Hybrid Write Barrier, 大幅减少了第二次STW的时间

        |go程序在高并发时内存占用大的问题
            |原因
                1.gc阈值动态增大 -> go的垃圾回收有个触发阈值，这个阈值会随着每次内存使用变大而逐渐增大（如初始阈值是10MB则下一次就是20MB，再下一次就成为了40MB…）,如果长时间没有触发gc,go会'每两分钟主动触发'一次。高峰时内存使用量上去后，除非持续申请内存，靠阈值触发gc已经基本不可能，而是要等最多2min主动gc开始才能触发gc
                2.内存延迟回收 -> go语言在向系统交还内存时只是告诉系统这些内存不再使用了，可以回收；但操作系统并不是立即回收，而是等到系统内存紧张时才会回收，这样该程序重新申请内存时就可以获得极快的分配速度
            |解决方案 -> 当程序由于'高并发造成大量小对象'的内存问题时，最好可以使用sync.Pool等'对象池'技术，避免大量小对象加大 GC 压力
                |sync.Pool -> 设计的目的是存放已经分配的但是暂时不用的对象，在需要用到的时候直接从pool中取. sync.Pool严格意义上来说是一个临时对象池，适用于储存一些会在goroutine间分享的'临时对象'。主要作用是减少GC，提高性能。在Golang中最常见的使用场景是'fmt包中的输出缓冲区'
                    -> Pool中的对象会在没有任何通知的情况下被'自动移除'掉。实际上，这个清理过程是在'每次垃圾回收之前'做的。垃圾回收是固定两分钟触发一次。而且每次清理会将Pool中的所有对象都清理掉
                    -> Get方法并不会对获取到的对象值做任何的保证，因为放入本地池中的值有可能'会在任何时候被删除'，但是不通知调用者。放入共享池中的值有可能被其他的goroutine偷走。 所以对象池比较适合用来存储一些临时且状态无关的数据，但是不适合用来存储数据库连接的实例，因为存入对象池重的值有可能会在垃圾回收时被删除掉，这违反了数据库连接池建立的初衷
                    val := "Hello,World!" // 准备放入的字符串
                    Pool.Put(val) // 放入
                    v := Pool.Get() // 取出
                    v1 := Pool.Get() // 再取就没有了,会自动调用NEW

                    package main
                    import (
                        "fmt"
                        "io"
                        "net/http"
                        "sync"
                    )
                    // 并发过程使用了多少次 []byte
                    var mu sync.Mutex
                    var holder map[string]bool = make(map[string]bool)
                    // 临时对象池
                    var p = sync.Pool{
                        New: func() interface{} {
                            buffer := make([]byte, 1024)
                            return &buffer
                        },
                    }
                    func readContent(wg *sync.WaitGroup) {
                        defer wg.Done()
                        resp, err := http.Get("http://my.oschina.net/xinxingegeya/home")
                        if err != nil {
                            fmt.Println(err)
                        }
                        defer resp.Body.Close()
                        byteSlice := p.Get().(*[]byte) //类型断言
                        key := fmt.Sprintf("%p", byteSlice)
                        mu.Lock()
                        _, ok := holder[key]
                        if !ok {
                            holder[key] = true
                        }
                        mu.Unlock()
                        _, err = io.ReadFull(resp.Body, *byteSlice)
                        if err != nil {
                            fmt.Println(err)
                        }
                        p.Put(byteSlice)
                    }
                    func main() {
                        var wg sync.WaitGroup
                        for i := 0; i < 10; i++ {
                            wg.Add(1)
                            go readContent(&wg)
                        }
                        wg.Wait()
                        for key, val := range holder {
                            fmt.Println("Key:", key, "Value:", val)
                        }
                    }

        |goroutine泄露的问题
            -> 我们的一个服务需要处理很多长连接请求，实现时，对于每个长连接请求各开了一个读取和写入协程，全部采用endless for loop不停地处理收发数据。当连接被远端关闭后，如果不对这两个协程做处理，他们依然会一直运行，并且占用的channel也不会被释放…这里就必须十分注意，在不使用协程后一定要把他依赖的channel close并通过再协程中判断channel是否关闭以保证其退出

|最佳实践
    1.减少对象分配 所谓减少对象的分配，实际上是尽量做到，对象的重用。 比如像如下的两个函数定义：
        -> 第一个函数没有形参，每次调用的时候返回一个 []byte，第二个函数在每次调用的时候，形参是一个 buf []byte 类型的对象，之后返回读入的 byte 的数目。
        -> 第一个函数在每次调用的时候都会分配一段空间，这会给 gc 造成额外的压力。第二个函数在每次迪调用的时候，会重用形参声明
    2.string 与 []byte 转化 在 stirng 与 []byte 之间进行转换，会给 gc 造成压力 通过 gdb，可以先对比下两者的数据结构
        -> 两者发生转换的时候，底层数据结结构会进行复制，因此导致 gc 效率会变低。解决策略上，一种方式是一直使用 []byte，特别是在数据传输方面，[]byte 中也包含着许多 string 会常用到的有效的操作。另一种是使用更为底层的操作直接进行转化，避免复制行为的发生。主要是使用 unsafe.Pointer 直接进行转化.可以把 unsafe.Pointer 理解成 c++ 中的 void*，在 golang 中，相当于是各种类型的指针进行转化的桥梁
        -> 关于 uintptr 的底层类型是 int，它可以装下指针所指的地址的值。它可以和 unsafe.Pointer 进行相互转化，主要的区别是，uintptr 可以参与指针运算，而 unsafe.Pointer 只能进行指针转化，不能进行指针运算。具体指针运算的时候，要先转成 uintptr 的类型，才能进一步计算，比如偏移多少之类的
    3.少量使用+连接 string 由于采用 + 来进行 string 的连接会'生成新的对象'，降低 gc 的效率，好的方式是通过 append 函数来进行
