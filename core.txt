\Python
    |Memory
    -> 所有对象和数据结构都在一个私有heap中,程序员没有访问该heap的权限,只有解释器才能进行操作
    -> 内存管理模块为Python的heap空间分配内存.其核心API提供一些访问该模块的方法供程序员使用
    垃圾回收 -> 1.引用计数 2.标记清除 3.分代回收

    1.看过的书 -> python参考手册, mysql技术内幕
    2.谈谈python的装饰器,迭代器,yield
        |可以直接用于for循环的对象统称为可迭代对象('{Iterable}')
        -> 实现了__iter__方法
        1.集合数据类型,如list、tuple、dict、set、str等
        2.generator,包括生成器和带yield的generator function

        |可以被next()函数调用并不断返回下一个值的对象是Iterator(迭代器)
        -> 实现了__iter__和(__next__(python3.x)|next(python2.x))方法
        -> __iter__返回迭代器自身,__next__返回容器中的下一个值
        -> Iterator对象表示的是一个数据流,可以被next()函数调用并不断返回下一个数据,直到没有数据时抛出'{StopIteration}'错误.这个数据流是一个有序序列,我们'{不能提前知道序列长度}',只能不断通过next()函数实现按需计算下一个数据,所以Iterator的计算是'{惰性}'的,只有在需要'{返回下一个数据}'时它才会计算
        -> 生成器是一种特殊的'{Iterator}',不需要实现__iter__和__next__,只需yiled关键字
        -> list、dict、str不是'{Iterator}'
        -> iter()可以把list、dict、str等变成'{Iterator}' -> iter([]),iter('abc')
        -> Python的for循环就是通过不断调用next()函数实现的(for = loop(next(iterator)))
            > for x in [1, 2, 3, 4, 5]:
            >     pass
            -> 等价于
            > it = iter([1, 2, 3, 4, 5]) > #首先获得Iterator对象
            > while True: #循环
            >     try:
            >         x = next(it) #获得下一个值
            >     except StopIteration:
            >         break #遇到StopIteration就退出循环

    3.标准库线程安全的队列是哪一个？不安全的是哪一个？logging是线程安全的吗？
        线程安全 -> 多线程同时操作时不会发生写冲突
        非线程安全 -> 多线程同时操作时会发生写冲突
        -> Queue模块提供一个适用于多线程编程的先进先出(first-in,first-out,FIFO)数据结构,可以用来在生产者消费者'{线程之间安全}'地传递消息或其他数据.它会为调用者'{处理锁定}',使用多线程可以安全地处理同一个Queue实例
        -> list,set,dict是'{非线程安全}'的
        -> logging是线程安全的,handler内部使用了threading.RLock()来保证同一时间只有一个线程能够输出

    4.python适合的场景有哪些？当遇到计算密集型任务怎么办？
        -> 运维,爬虫,数据分析,web
        -> 遇到'{计算密集型}'任务使用'{多进程}',利用多核

    5.python高并发解决方案？
        '{python2.x}' -> twisted+tornado+gevent, socket消息队列轮询
        '{python3.x}' -> asyncio

    -> Flask&Celery&RabbitMQ&MongoDB&Asyncio&RESTful API
    -> 网络爬虫(beautifulsoup -> 简单, scrapy -> 复杂复杂)
    -> 搜索引擎Solr搭建

    |注释 -> docstring
    > """
    > xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    > """

    -> DataStructure(String, Array, Queue, Stack, Tree, List, Hash)
    -> Network(ProcessMsg,Socket,MultipleThread,Coroutine,Gevent,Asyncio,RabbitMQ)

\Linux
    -> 用户态/内核态传递数据
        -> 为了限制不同程序之间的访问能力,防止它们获取别的程序或外围设备的内存数据,并发送到网络,CPU划分出两个权限等级 -> 用户态和内核态(内存安全)
        内核态(CPU) -> 可访问内存所有数据,包括外围设备(硬盘,网卡).也可以从一个程序切换到另一个
        用户态 -> 只能访问受限内存,不能访问外围设备.占用CPU的能力被剥夺,CPU资源可以被其他程序获取
        -> 系统调用是操作系统的最小功能单位(memory, IO(file&network), process, devices)
        -> 用户空间的应用程序,通过'{系统调用}',进入内核空间.这个时候用户空间的进程要传递很多变量、参数的值给内核,内核态运行的时候也要保存用户进程的一些寄存器值、变量等.所谓的“进程上下文”,可以看作是用户进程传递给内核的这些参数以及内核要保存的那一整套的变量和寄存器值和当时的环境等

	-> Systemtap/DTrace #收集操作系统和JVM中的性能瓶颈
	-> tcpdump #抓包工具,将网络中传送的数据包的头部完全截获下来提供分析
    -> cron #周期执行任务的守护进程来处.cron读取一个或多个配置文件,这些配置文件中包含了命令行及其调用时间.cron的配置文件称为crontab,是cron table的简写

	|nice #调整程序运行的优先级
	nice (-n 10)/(--adjustment=10) proc/(-p pid)/(-u username) #将进程的VI值设为10
	-> 'renice'用于改变'{正在运行}'的进程的niceness值
	-> 'nice'是指'niceness',即友善度、谦让.在进程中表示进程的优先级,也即进程的友善度.niceness值为负时,表示'{高优先级}',能'{提前执行}'和'{获得更多的资源}',对应低友善度;反之,则表示低优先级,对应高友善度

	|Load
	-> uptime #查看linux系统负载
		> 04:03:58 up 10 days, 13:19, 1 user, load average: 0.54, 0.40, 0.20
		1.当前时间 -> 04:03:58
		2.主机已运行时间,时间越大,说明你的机器越稳定 -> 10 days, 13:19
		3.当前用户连接数,是总连接数而不是用户数 -> 1 user
		4.'{平均负载}' -> 0.54, 0.40, 0.20,最近1分钟、5分钟、15分钟系统的负载
			-> 在特定时间间隔内'{运行队列}'中的'{平均进程数}'
	-> 如果一个进程满足以下条件则其就会位于运行队列中
		1.它没有在等待I/O操作的结果
		2.它没有主动进入等待状态(也就是没有调用'wait')
		3.没有被停止(例如:等待终止)
	-> 一般来说,每个CPU内核当前活动进程数(平均数)不大于3,则系统运行表现良好;每个CPU内核的任务数大于5,那么这台机器的性能有严重问题.如果你的主机是4核cpu的话,那么只要uptime最后输出的'{load average}'数值小于12即表示系统负载不是很严重;如果达到20,那就表示当前系统负载非常严重,估计打开执行web脚本非常缓慢

\Mysql
    1.谈谈mysql字符集和排序规则？
    2.varchar与char的区别是什么？大小限制？utf8字符集下varchar最多能存多少个字符
    3.primary key和unique的区别？
    4.外键有什么用,是否该用外键？外键一定需要索引吗？
    5.myisam与innodb的区别？innodb的两阶段锁定协议是什么情况？
    6.索引有什么用,大致原理是什么？设计索引有什么注意点？
    7.分库分表
    8.mysql-redis集群
    9.数据库设计

\Redis
    |原理
    1.Redis内部使用一个'{redisObject}'对象来表示所有的key和value
    2.Redis的Hash实际是内部存储的'{Value}'为一个HashMap,并提供了直接存取这个Map成员的接口,解决了重复存储数据的问题
    3.Redis的list是每个子元素都是String类型的'{双向链表}',可以通过push和pop操作从列表的头部或者尾部添加或者删除元素,这样List'{既可以作为栈,也可以作为队列}'
    4.Redis的Set是String类型的无序hashtable,概念和数学中个的集合基本类似,可以交集(redis.sinter),并集(redis.sunion),差集(redis.sdiff)等等,set中的元素是没有顺序的,可以'{自动排重}'
    5.基于程序的'{局部性访问原理}',CPU访问内存而不是磁盘,这大大提升了运行的速度

    |特性
    1.开源免费
    2.原子性 -> 事务操作命令('{单线程}',不能打断,不能回滚,支持多操作合并后事务操作)
    3.多数据类型 -> string,list,set,sorted-set,hashset,'{比memcached多很多}'
    4.快速运算 -> '{内存}'数据库(读的速度是110000次/s,写的速度是81000次/s)
    5.数据持久化 -> 保存数据(rdb | aof)文件到磁盘,重启时再次加载使用
    6.丰富的特性 -> 支持publish/subscribe,通知,key过期等特性
    7.master-slave模式数据备份 -> 可建立高性能读写分离服务器集群
    8.'{单线程问题}'
    -> 一条命令搞死Redis.例如:keys * (建议禁用该命令并用scan替代)、对一个巨大的hash key(例如含有上亿元素的hash key)执行hget all、执行一个巨型的set bit等等,因为Redis是单线程的,在出现这些请求的时候由于它们执行速度极其缓慢而Redis的每秒请求量又比较大,因此在这些请求执行完毕前其它所有请求都会被阻塞住

    1.什么场景用redis,为什么mysql不适合？
        1.会话缓存(Session Cache)-> Redis优势在于提供'{持久化}'
        2.全页缓存(FPC)-> 有磁盘的持久化,即使重启Redis实例,用户也不会看到页面加载速度的下降
        3.消息队列 -> 提供list和set操作,这使得Redis能作为一个很好的消息队列平台来使用
        4.排行榜/计数器 -> Redis在内存中对'{数字增减}'的操作实现的非常好.集合(Set)和有序集合(Sorted Set)也使得我们在执行这些操作的时候变的非常简单
        5.'{数据变化快}'的应用 -> 消息队列, 排行榜, 计数器, 时间线, 关注列表, 股票交易

        -> mysql的'{磁盘IO}'操作,数据排序,表关联,锁机制
        -> 一般来说,写入数据是直接到mysql,读取的是redis. mysql->redis同步数据

    2.谈谈redis的事务？用事务模拟原子+1操作？原子操作还有其它解决方案吗？
        > watch intA
        > intA_tmp = intA + 1
        > multi
        > set intA intA_tmp
        > exec

    3.redis内存满了会怎么样？
        1.主库宕机('{主从切换代价大}')
        -> redis在主库挂掉以后,从库升级为新的主库.那么'{切换主库}'以后,所有的从库都需要跟新主做一次全同步,代价非常大
        2.扩容('{扩容时间长}')
        -> 很多时候会出现流量的突发性增长,通常在找到原因之前我们的应急做法就是扩容.根据经验,一个20G的redis扩容一个从库需要将近20分钟
        3.网络不好导致从库重做最终引发雪崩效应('{主从同步代价大}')
        -> 该场景的最大问题是主库与从库的同步中断,而此时很可能从库仍然在接受写入请求,那么一旦中断时间过长同步缓冲区就很可能被复写.此时从库上一次的同步位置已丢失,在网络恢复后虽然主库没有发生变化但由于从库的同步位置丢失了'{从库必须进行重做}'.如果此时主库内存体积过大那么从库重做速度就会很慢,而发送到从库的读请求就会受到严重影响,同时由于传输的rdb文件的体积过大,主库的网卡在相当长的一段时间内都会受到严重影响
        4.内存越大,触发持久化的操作'{阻塞主线程的时间越长}'
        -> Redis是单线程的内存数据库,在redis需要执行耗时的操作时,会fork一个新进程来做,比如bgsave,bgrewriteaof. Fork新进程时,虽然可共享的数据内容不需要复制,但会复制之前进程空间的内存页表,这个复制是主线程来做的,会阻塞所有的读写操作,并且随着内存使用量越大耗时越长.例如:内存20G的redis,bgsave复制内存页表耗时约为750ms,redis主线程也会因为它阻塞750ms
        5.'{内存太贵}'

        |解决办法 -> 极力减少内存的使用
        1.设置'{过期时间}' -> 对具有时效性的key设置过期时间,redis自身有过期key清理策略
        2.不存放垃圾到redis中,及时'{清理无用数据}'
        -> 例如一个redis承载了3个业务的数据,若有两个业务下线,就及时清理这两个业务的相关数据
        3.'{数据压缩}' -> 例如一些长文本形式的数据,压缩能够大幅度降低内存占用
        4.关注内存增长并'{定位大容量key}'
        -> 分析redis实例中哪些key比较大从而快速定位异常key(非预期增长的key,往往是问题之源)
        5.'{pika}'
        -> 360DBA和基础架构组联合开发的'{类redis存储系统}',使用Redis协议,兼容redis绝大多数命令(String,Hash,List,ZSet,Set),'{不需要修改任何代码}',就可以将服务迁移至pika
        -> 如果实在不想搞的那么累,那就把业务迁移到新开源的pika上面,这样就不用太关注内存了,redis内存太大引发的问题,那也都不是问题了
        -> pika使用的是'{多线程}'模型,使用多个工作线程来进行读写操作,线程分为11种
        '{容量大}' -> Pika没有Redis的内存限制,最大使用空间等于磁盘空间的大小
        '{加载db速度快}' -> Pika在写入的时候,数据是落盘的,所以即使节点挂了,不需要rdb或者aof,pika重启不用重新加载数据到内存而是直接使用已经持久化在磁盘上的数据,不需要任何数据回放操作(除去少量rocksdb自身的recover),这大大降低了重启成本
        '{备份速度快}' -> Pika备份的速度大致等同于cp的速度(拷贝数据文件后还有一个快照的恢复过程,会花费一些时间),目前已经开发完更快更省空间的秒级备份,即将投入使用,这样在对于百G大库的备份是快捷的,更快的备份速度更好的解决了主从的全同步问题
        -> 存储引擎是rocksdb,性能比Redis低一些,一般使用SSD盘来存放数据

\操作系统(Linux)
    tcp/ip协议 -> ???????????

    1.tcp/udp的区别？tcp粘包是怎么回事,如何处理？udp有粘包吗？
        |保护消息边界 -> 把每条数据当作'{独立的消息}'传输,接收端一次只能接收一个数据包
        |流传输 -> '{无保护消息边界}',如果发送端连续发送数据,接收端可能一次收到多个数据包

        |TCP
        -> 基于连接(需三次握手建立),对系统资源要求较多,包头结构复杂,保证数据正确性和顺序
        -> TCP为了保证可靠传输,'{减少额外开销}'(每次发包都要验证),采用了'{流传输}',相对于面向消息的传输,可以减少包的发送量,减少开销

        |TCP粘包 -> 只在'{流传输}'中出现
        -> 客户端与服务器会维持一个连接(Channel),数据在连接不断开的情况下,可以持续不断地将多个数据包发往服务器.如果发送的数据包太小,那么会启用Nagle算法(可配置是否启用)'{对较小的数据包进行合并}'(因此'{TCP的网络延迟比UDP的高}')然后再发送(缓冲区满、超时或者包大小足够).这样服务器在接收到数据流的时候就无法区分哪些数据包是客户端自己分开发送的,就产生了粘包；如果服务器消息没有被及时从缓存区取走,下次在取数据的时候可能就会出现'{一次取出多个数据包}'的情况,导致粘包(确切来讲,对于基于TCP协议的应用,不应用包来描述,而应用流来描述)
            |解决办法
            1.对于发送方引起的粘包,用户可通过编程设置来避免,TCP提供了'{强制数据立即传送}'的指令push,服务器收到push指令后,将本段数据'{即时发送}'出去,而不必等待发送缓冲区满
            2.对于接收方引起的粘包,可通过优化程序设计、精简接收进程工作量、提高接收进程优先级等措施,使其'{及时接收}'数据,从而尽量避免出现粘包现象
            3.封装待传输数据包时,用固定'{分隔符}'作为结尾符(数据中不能含结尾符),这样我们接收到数据后,如果出现结尾符,即人为将粘包分开;如果包中没有出现结尾符,则认为是分包,等待下个包中出现结尾符时合并成一个完整的包(常用于文本传输数据,如采用/r/n之类的分隔符)
            4.在数据包的固定位置封装'{数据包的长度信息}'(或可计算数据包总长度的信息),服务器接收到数据后,先是解析包长度,然后根据包长度截取数据包(常用于自定义协议中)

        |UDP
        -> 无连接,对系统资源要求较少,包头结构简单,不保证数据正确性和顺序,面向'{数据报}'传输
        -> 作为无连接不可靠的传输协议(适合频繁发送较小包),有'{保护消息边界}','{不会对数据包进行合并}',数据直接发出去,因此'{不会出现粘包}',每一个数据包也都是完整的(数据+UDP头+IP头等等发一次数据封装一次)

    2.time_wait是什么情况？出现过多的close_wait可能是什么原因？
        |MSL(MaximumSegmentLifetime,最大分节生命期) -> 一个数据包在网上的'{最长生存时间}',超过这个时间数据包将消失.RFC1122上建议是2分钟,berkeley的TCP实现传统上是30秒
        -> 通信双方建立TCP连接后,'{主动关闭连接}'的一方会进入TIME_WAIT状态
        -> TIME_WAIT状态维持时间是'{两个MSL}'时间长度,即1-4分钟.Windows系统是4分钟
        -> 主动关闭连接的一端会发送最后一个ack,然后进入TIME_WAIT状态,停留2个MSL时间后进入CLOSED状态
            |原因
            1.可靠地实现TCP全双工连接的终止
            -> TCP协议在关闭连接的四次握手过程中,最终的ACK是由主动关闭连接的一端(后面统称A端)发出的,如果这个ACK丢失,对方(后面统称B端)将重发出最终的FIN,因此A端必须维护状态信息(TIME_WAIT)允许它重发最终的ACK.如果A端不维持TIME_WAIT状态,而是处于CLOSED 状态,那么A端将响应RST分节,B端收到后将此分节解释成一个错误(在java中会抛出connection reset的SocketException)
            因此要实现TCP全双工连接的正常终止,必须处理终止过程中四个分节任何一个分节的丢失情况,主动关闭连接的A端必须维持TIME_WAIT状态
            2.允许老的重复分节在网络中消失
            -> TCP分节可能由于路由器异常而"迷途",在迷途期间,TCP发送端可能因确认超时而重发这个分节,迷途的分节在路由器修复后也会被送到最终目的地,这个迟到的迷途分节到达时可能会引起问题.在关闭前一个连接之后,马上又重新建立起一个相同的IP和端口之间的新连接,前一个连接的迷途重复分组在前一个连接终止后到达,而被新连接收到了.为了避免这个情况,TCP协议不允许处于TIME_WAIT状态的连接启动一个新的可用连接,因为TIME_WAIT状态持续2MSL,就可以保证当成功建立一个新TCP连接的时候,来自旧连接重复分组已经在网络中消失

        |过多close_wait -> 被动关闭方未关闭socket造成
            |原因
            -> 在服务器与客户端通信过程中,因服务器未关闭socket导致closed_wait发生,致使监听port打开的句柄数到了1024个(每个用户默认分配的句柄上限),且均处于close_wait的状态,最终造成配置的port被占满出现“Too many open files”,无法再进行通信
            -> linux在文件句柄的数目上有两个级别的限制('{系统级限制和针对用户的限制}').一般情况下1024也够用了,但是在频繁使用网络IO和文件IO的大容量系统上,句柄很快就被耗光了
            -> 有两种限制(soft&hard),数目超过soft时warning警告,达到hard时系统将拒绝或异常

            |解决办法
            1.设置超时
            -> 原因是调用ServerSocket类的accept()方法和Socket输入流的read()方法时会引起线程阻塞,所以应该用setSoTimeout()方法设置超时(缺省的设置是0,即超时永远不会发生);超时的判断是累计式的,一次设置后,每次调用引起的阻塞时间都从该值中扣除,直至另一次超时设置或有超时异常抛出
            比如,某种服务需要三次调用read(),超时设置为1分钟,那么如果某次服务三次read()调用的总时间超过1分钟就会有异常抛出,如果要在同一个Socket上反复进行这种服务,就要在每次服务之前设置一次超时

            2.修改配置
            |增加 -> /etc/security/limits.conf #保存后reboot
                username(* -> 所有用户) soft nofile 65535 #软限制
                username hard nofile 65535 #硬限制

            |系统级句柄数限制修改
                sysctl -w fs.file-max 65536
             or echo "65536" > /proc/sys/fs/file-max
             or echo "fs.file-max=65536" >> /etc/sysctl.conf #修改内核参数

            |优先级(Open File Descriptors)
                soft<hard<kernel<最大file descriptor数采用的数据结构所导致的限制

            3.使用'{连接池}'来控制连接数

    3.epoll,select的区别？边缘触发,水平触发区别？
        |epoll
        epoll fd -> socket描述符
        多路复用IO模型 -> 监视多个fd,一旦某个fd就绪(读就绪或写就绪),通知程序进行相应的读写操作
        -> 只轮询EventQueue,一个进程能打开的FD数目没有1024的限制=n*10W(系统内存nGB)
        -> epoll_wait()获取就绪fd时,返回的并不是实际的描述符,而是一个代表就绪描述符数量的值,拿到这些值去EventQueue中依次取得相应数量的文件描述符即可.使用'{内存映射}'(mmap)技术,避免了复制大量文件描述符带来的开销
        running -> epoll_create(epoll instance) -> epoll_ctl(create RB-Tree & EventQueue for socket on epoll instance) -> epoll_ctl(insert socket into RB-Tree and register Callback on kernel) -> data sent to a socket -> kernel(execute Callback, activate the socket to readable/writeable/etc., put it into EventQueue and inform epoll_wait) -> epoll_wait(get socket from EventQueue, send socket to UserState then read/write/etc. data on socket)

        |select
        -> 获取就绪fd时轮询,遍历全部socket,一个进程能打开的'{FD数目有限制}'(默认1024)
        -> 轮询时会将所有socket从用户态'{复制}'到内核态.随着fd量的增长,此复制开销也会线性增长

        |边缘触发(Edge Triggered) -> Nginx-epoll默认工作方式
        -> 只有在监视的文件句柄上'{发生事件}'的时候ET模式才会通知进程fd准备就绪,之后不再通知
        |水平触发(level triggered) -> epoll'{默认}'工作方式
        -> 没有任何操作,内核还是会一直通知你一个fd是否就绪,这种模式编程'{出错误可能性小}'一点.传统的select/poll都是这种模型的代表
