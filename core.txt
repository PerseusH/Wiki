\Python
    -> RESTful API
    -> Algrithm(String, Array, Queue, Stack, Tree, List, Hash)
    -> Network(Process Message, Socket, Multiple Thread, Coroutine)
        进程fd -> 进程文件描述符
        GIL -> Global Interpreter Lock,全局解释器锁,解释器执行代码时,任何Python线程执行前,必须先获得GIL锁,然后,每执行100条字节码,解释器就自动释放GIL锁,让别的线程有机会执行.这个GIL全局锁实际上把所有线程的执行代码都给上了锁,所以,多线程在Python中只能交替执行,即使100个线程跑在100核CPU上,也只能用到1个核,在官方解释器上不能利用多核实现真正的多线程
        -> 多线程模式一旦线程数目过多, CPU切换线程的开销也会很大
        -> 多线程致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃,因为所有线程共享进程的内存

        |IO
            |同步IO
            -> 在一个线程中,CPU执行代码的速度极快,一旦遇到IO操作,如读写文件,发送网络数据时,就需要等待IO操作完成,才能继续进行下一步操作:
            > do_some_code()
            > f = open('/path/to/file', 'r')
            > r = f.read() -> <== 线程停在此处等待IO操作结果
            > #IO操作完成后线程才能继续执行
            > do_some_code(r)

            |异步IO
            -> 当代码需要执行一个耗时的IO操作时,它只发出IO指令,并不等待IO结果,然后就去执行其他代码了.一段时间后,当IO返回结果时,再通知CPU进行处理
            -> 异步IO模型需要一个消息循环,在消息循环中,主线程不断重复"读取-处理消息"这一过程:(消息模型)
            > loop = get_event_loop() #事件队列
            > while True:
                > event = loop.get_event()
                > process_event(event) #发送消息

        |corotine
        -> 事件驱动单线程的异步编程模型, 没有切换开销, 无需锁机制
        -> Python对协程的支持是通过generator实现的
        -> 在generator中, 我们不但可以通过for循环来迭代, 还可以不断调用next()函数获取由yield语句返回的下一个值或接收调用者发出的参数
        -> 多进程+协程, 既充分利用多核, 又充分发挥协程的高效率, 可获得极高的性能

\Linux
	-> Systemtap/DTrace #收集操作系统和JVM中的性能瓶颈
	-> tcpdump #抓包工具,将网络中传送的数据包的头部完全截获下来提供分析

	|nice #调整程序运行的优先级
	nice (-n 10)/(--adjustment=10) proc/(-p pid)/(-u username) #将进程的VI值设为10
	-> 'renice'用于改变'{正在运行}'的进程的niceness值
	-> 'nice'是指'niceness',即友善度、谦让.在进程中表示进程的优先级,也即进程的友善度.niceness值为负时,表示'{高优先级}',能'{提前执行}'和'{获得更多的资源}',对应低友善度;反之,则表示低优先级,对应高友善度

	|Load
	-> uptime #查看linux系统负载
		> 04:03:58 up 10 days, 13:19, 1 user, load average: 0.54, 0.40, 0.20
		1.当前时间 -> 04:03:58
		2.主机已运行时间,时间越大,说明你的机器越稳定 -> 10 days, 13:19
		3.当前用户连接数,是总连接数而不是用户数 -> 1 user
		4.'{平均负载}' -> 0.54, 0.40, 0.20,最近1分钟、5分钟、15分钟系统的负载
			-> 在特定时间间隔内'{运行队列}'中的'{平均进程数}'
	-> 如果一个进程满足以下条件则其就会位于运行队列中
		1.它没有在等待I/O操作的结果
		2.它没有主动进入等待状态(也就是没有调用'wait')
		3.没有被停止(例如:等待终止)
	-> 一般来说,每个CPU内核当前活动进程数(平均数)不大于3,则系统运行表现良好;每个CPU内核的任务数大于5,那么这台机器的性能有严重问题.如果你的主机是4核cpu的话,那么只要uptime最后输出的'{load average}'数值小于12即表示系统负载不是很严重;如果达到20,那就表示当前系统负载非常严重,估计打开执行web脚本非常缓慢

\Mysql
    |ACID
    A(Atomicity,原子性)
    -> 事务开始后所有操作,要么全部做完,要么全部不做,不可能停滞在中间环节.事务执行过程中出错,会回滚到事务开始前的状态,所有的操作就像没有发生一样
    C(Consistency,一致性)
    -> 事务开始前和结束后,数据库的完整性约束没有被破坏.比如A向B转账,不可能A扣了钱,B却没收到
    I(Isolation,隔离性)
    -> 同一时间,只允许一个事务请求同一数据,不同的事务之间彼此没有任何干扰.比如A正在从一张银行卡中取钱,在A取钱的过程结束前,B不能向这张卡转账
    D(Durability,持久性)
    -> 事务完成后,事务对数据库的所有更新将被保存到数据库,不能回滚
    -> '{原子性}'是事务隔离的'{基础}',隔离性和持久性是手段,'{最终目的}'是保持数据的'{一致性}'

    |事务隔离级别
    1.Read_Uncommitted(读取未提交内容)
    -> 在该隔离级别,所有事务都可以看到其他未提交事务的执行结果.本隔离级别很少用于实际应用,因为它的性能也不比其他级别好多少.读取未提交的数据,也被称之为脏读(Dirty Read)
    2.Read_Committed(读取提交内容)
    -> 这是'{大多数数据库系统}'的'{默认隔离级别}'(但不是MySQL默认的).它满足了'{隔离}'的简单定义:'{一个事务只能看见已提交事务所做的改变}'.这种隔离级别也支持所谓的不可重复读(Nonrepeatable Read),因为同一事务的其他实例在该实例处理期间可能有新的commit,所以同一select可能返回不同结果
    3.Repeatable_Read(可重读)
    -> 这是'{MySQL}'的'{默认事务隔离级别}',它确保同一事务的多个实例在并发读取数据时,会看到同样的数据行.不过理论上,这会导致另一个棘手的问题:幻读(Phantom Read).简单的说,幻读指当用户读取某一范围的数据行时,另一个事务又在该范围内插入了新行,当用户再读取该范围的数据行时,会发现有新的“幻影” 行.InnoDB和Falcon存储引擎通过多版本并发控制(MVCC,Multiversion Concurrency Control)机制解决了该问题
    4.Serializable(可串行化)
    -> 这是最高的隔离级别,它通过'{强制事务排序}',使之不可能相互冲突,从而'{解决幻读问题}'.简言之,它是在每个读的数据行上加上共享锁.在这个级别,可能导致大量的超时现象和锁竞争

    |事务的并发问题
    1.'脏读' -> 事务A读取了事务B更新的数据,然后B回滚操作,那么A读取到的数据是脏数据
    2.'不可重复读' -> 事务A多次读取同一{据,事务B在事务A多次读取的过程中,对数据作了更新并提交,导致事务A多次读取同一数据时,结果不一致
    3.'幻读' -> 系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级,但是系统管理员B就在这个时候插入了一条具体分数的记录,当系统管理员A改结束后发现还有一条记录没有改过来,就好像发生了幻觉一样,这就叫幻读
    -> 不可重复读的和幻读很容易混淆,不可重复读侧重于修改,幻读侧重于新增或删除.解决不可重复读的问题只需锁住满足条件的行,解决幻读需要锁表

    事务隔离级别	               脏读	不可重复读	幻读
    读未提交(read-uncommitted)  是	   是	    是
    不可重复读(read-committed)  否	  是        是
    可重复读(repeatable-read)   否	   否        是
    串行化(serializable)	     否	    否        否

\Redis
    1.开源免费
    2.原子性 -> 事务操作命令(单线程, 不能打断, 不能回滚, 支持多操作合并后事务操作)
    3.多数据类型 -> string, list, set, sorted set, hash obj
    4.快速运算 -> '{内存}'数据库(读的速度是110000次/s, 写的速度是81000次/s)
    5.数据持久化 -> 保存数据(rdb | aof)文件到磁盘, 重启时再次加载使用
    6.丰富的特性 -> 支持publish/subscribe, 通知, key过期等特性
    7.master-slave模式数据备份 -> 可建立高性能读写分离服务器集群
