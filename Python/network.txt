|进程fd -> 进程文件描述符

|死锁 -> 假设有两个全局资源，a和b，有两个线程thread1，thread2. thread1占用a，想访问b，但此时thread2占用b，想访问a，两个线程都不释放此时拥有的资源，并互相等待，那么就会造成死锁
    -> 单线程异步IO

-> 大数据处理的效率在于良好的分布计算逻辑(并行计算),而不是什么语言.'{瓶颈在IO}',使用SSD硬盘解决

\IO
    |同步IO
    -> 在一个线程中,CPU执行代码的速度极快,一旦遇到IO操作,如读写文件,发送网络数据时,就需要等待IO操作完成,才能继续进行下一步操作:
    > f = open('/path/to/file','r')
    > r = f.read() #线程停在此处等待IO操作结果
    > #IO操作完成后线程才能继续执行
    > do_something(r)

    |异步IO
    -> 当代码需要执行一个耗时的IO操作时,它只发出IO指令,并不等待IO结果,然后就去执行其他代码了.一段时间后,当IO返回结果时,再'{回调}'通知CPU进行处理
    -> 异步IO模型需要一个消息循环,在消息循环中,主线程不断重复"读取-处理消息"这一过程:(消息模型)
    > loop = get_event_loop() #事件队列
    > while True:
        > event = loop.get_event()
        > process_event(event) #发送消息

    |协程/多线程并发
        阻塞 -> 挂起当前过程 -> 切换至其他过程运行 -> 阻塞完毕,过程就绪 -> 执行过程剩余代码

        |阻塞原因
            1.disk IO
            2.network IO
            3.time.sleep(n)
            4.gevent.sleep(n)
            5.threading.Condition().wait()
            6.threading.lock().aquire()

\Coroutine
    -> '{用户态}'的轻量级线程, 切换时不需要陷入系统调用(system call)(不会进入内核态)
    -> 事件驱动'{单线程}'的'{异步}'编程模型,'{没有切换开销}','{无需锁}',但无法利用多核资源
    -> Python对协程的支持是通过'{generator}'的'{yield + gen.send(n)}'实现的
    -> 在generator中,我们不但可以通过for循环来迭代,还可以不断调用next()函数获取由yield语句返回的下一个值或接收调用者发出的参数
    -> 协程拥有自己的本地寄存器'{上下文和栈}'，与其它协程共享全局数据和其它资源。协程切换时，将寄存器上下文和栈保存到其他地方(保存运行状态); 切回来的时候，恢复先前保存的寄存器上下文和栈
    -> 协程能保留上一次调用时的状态（即所有局部状态的一个特定组合），每次过程重入时，就相当于进入上一次调用的状态，换种说法：进入上一次离开时所处逻辑流的位置
    -> 多线程请求返回是无序的，哪个有数据返回就处理哪个，而协程程序是'{有序}'的，'{更容易调试}'
    -> 单线程执行，处理密集CPU和本地磁盘IO时性能较低。处理'{网络IO}'性能比较高
    -> 目前主流语言基本上都选择了多线程作为并发措施，与线程相关的概念是抢占式多任务（Preemptive multitasking），而与协程相关的是'{协作式多任务}'
    -> 不管是'{进程还是线程}'，每次阻塞、切换都需要陷入系统调用(system call)(用户态进入内核态)，因此上下文切换代价大.先让CPU跑操作系统的调度程序，然后再由调度程序决定该跑哪一个进程(线程)。而且由于抢占式调度'{执行顺序无法确定}'的特点，使用线程时需要非常小心地处理同步问题，而协程完全不存在这个问题（事件驱动和异步IO也有同样的优点）
    -> 协程是用户自己来编写调度逻辑的，因此'{同一时间只有一个}'协程在运行，相当于单线程的能力，所以CPU不用去考虑怎么调度、切换上下文，省去了CPU的切换开销，所以协程在一定程度上又好于多线程
    -> 协程没有开销的限制，理论上可以有'{无限个}'，把20W条url放在单进程的协程里执行，完全没问题
    -> '{多进程+协程}',既充分'{利用多核}',又充分发挥'{协程的高效率}',可获得极高的性能
    -> 调度协程有CPU开销,保存协程上下文有内存开销,性能'{不如事件驱动异步回调}'的编程模型

    |gevent
        -> 基于libev的并发库。它为各种并发和网络相关的任务提供了整洁的API.主要模式是greenlet
        |greenlet -> 以C扩展模块形式接入Python的轻量级协程。greenlet全部运行在主程序操作系统进程的内部，但它们被协作式地调度
        -> gevent实现了python标准库里面大部分的阻塞式系统调用，包括socket、ssl、threading和select等模块，而将这些阻塞式调用变为'{协作式运行}'（monkey.patch_xxx()）
        -> monkey-patch充分利用了动态语言的灵活性，'{不改变源代码}'而对功能进行追加和变更,可以对现有的语言Api进行'{追加，替换，修改Bug}'，甚至性能优化等等
        -> 通过monkey-patch的monkey.patch_xxx()将python标准库中模块或函数改成gevent中的响应的具有协程的协作式对象。这样在不改变原有代码的情况下，将应用的阻塞式方法变成协程式的
        -> monkey-patch在socket、ssl、threading和select等模块中所有可能进行IO操作的地方加了一个标记，相当于gevent.sleep(n)，打了补丁后，这些操作一开始执行就会阻塞并切换协程

        |hub
        -> hub是gevent核心部件，依靠libev这个事件库，来'{调度}'所有的任务greenlet
        -> hub也是一个greenlet，就是所谓的'{main greenlet}'
        -> hub会首先启动，然后马上启动事件循环。也就是'{libev的loop}'
        -> hub保存在线程的本地数据中，所以说每个线程中只存在一个main hub
        -> hub是线程内唯一的，greenlet是线程独立的，每个线程有各自的greenlet栈
        -> 从main greenlet切换到普通greenlet之后，main greenlet是停止执行(阻塞)的。greenlet是安排合理的'{串行}'，从而看起来像是并行
        -> 由hub决定运行哪个greenlet
        -> 切换到main greenlet是指首先切换到hub.wait，然后在hub.wait中切换到hub，hub运行loop, loop监听到greenlet感兴趣的事件(IO完成, 定时器结束)后, 由hub.switch切换到发生事件的那个greenlet。主导整个过程的是libev的loop
        -> gevent.spawn(func)创建一个新的Greenlet，并注册到hub的loop上(func即该greenlet的run()方法)，调用gevent.joinall或者Greenlet.join的时候开始切换到hub, 由hub.switch切换到第一个greenlet开始执行self.run()
        -> gevent.joinall就是用来启动事件轮询并等待运行结果的
            |核心API
            loop.timer(seconds, ref=ref) #定时器
            gevent.sleep(n) -> hub.wait(loop.timer(seconds, ref=ref))
            切换协程 -> hub.switch()
            hub.run() -> loop.run() #这个loop理论上会一直循环，如果结束，那么表明没有任何监听的事件（包括IO 定时等）

        |调度顺序
            1.libev的loop依次执行gevent.joinall(list)中的任务, 遇到阻塞就切换到下一个
            2.loop监听到greenlet感兴趣的事件(IO完成,定时器结束)后,切换到发生事件的greenlet

        > #执行到IO操作或gevent.sleep(n)阻塞时，gevent自动切换协程
        > from gevent import monkey; monkey.patch_socket() #monkey.patch_all()
        > import gevent
        >
        > def f(n):
        >     for i in range(n):
        >         print gevent.getcurrent(), i
        >
        > g1 = gevent.spawn(f, 5) #Greenlet对象, f本质是回调函数
        > g2 = gevent.spawn(f, 5)
        > g3 = gevent.spawn(f, 5)
        > g1.join()
        > g2.join()
        > g3.join()
        > #gevent.joinall([g1, g2, g3]) #会阻塞当前流程，并执行所有给定的greenlet，执行流程只会在所有greenlet执行完后才会继续向下走

\Process&Thread
    |GIL -> Global Interpreter Lock,全局解释器锁,解释器执行代码时,任何Python线程执行前,必须'{先获得GIL锁}',然后,每执行100条字节码,当前线程就会阻塞(time.sleep(n)),解释器就自动释放GIL锁,让别的线程有机会执行.这个GIL全局锁实际上把所有线程的执行代码都给上了锁,所以,'{多线程}'在Python中只能交替执行,即使100个线程跑在100核CPU上,也只能用到1个核,在官方解释器上'{不能用多核}'实现真正的多线程
    -> Python进程有各自独立的GIL锁

    -> 进程是并发执行的程序在执行过程中分配和管理资源的基本单位
    -> 进程有自己的内存空间，数据栈等，只能使用进程间通讯（interprocess communication, IPC），不能直接共享信息
    -> 线程是CPU调度的基本单位.计算机软硬件资源的分配与线程无关，线程只能共享它所属进程的资源
    -> 进程拥有一个完整的虚拟地址空间，不依赖于线程而独立存在；线程是进程的一部分，没有自己的地址空间，与进程内的其他线程一起共享分配给该进程的所有资源
    -> 每个进程都有进程控制表(PCB)，每个线程也有自己的线程控制表(TCB)
    -> 进程至少有 5 种基本状态，它们是：初始态，执行态，等待状态，就绪状态，终止状态
    -> 线程只有 3 个基本状态：就绪，执行，阻塞.存在 5 种基本操作来切换线程的状态：派生，阻塞，激活，调度，结束
    -> python里的线程是操作系统的真实线程
    -> 多线程模式一旦线程数目过多,CPU切换线程的开销也会很大
    -> 在8核16线程服务器上测试最大可以同时开启4792个线程(600/核)
    |'{线程不安全}' -> 每个线程互相独立，相互之间没有任何关系，但是在同一个进程中的线程，资源是共享的，如果不进行资源的合理分配，对数据造成破坏，使得线程运行的结果不可预期
    -> 其它的语言也有类似的情况,线程本身的特点导致线程的适用范围是受限的.只有CPU过剩,而其它的任务很慢,此时用线程才是有益的,可以很好平衡等待时间,提高并发性能
    -> 线程的问题主要是线程的安全稳定性.线程无法强制中止,同时线程与主进程共享内存,可能会影响主进程的内存管理
    -> '{多线程致命的缺点}'就是任何一个线程挂掉都可能直接造成整个进程崩溃,因为所有线程共享进程的内存
    -> 那么怎么解决呢？通过我们用进程方式.子进程崩溃后,会完全的释放所有的内存和错误状态.所以进程更安全. 另外通过进程,python可以很好的绕过GIL,这个全局锁问题
    -> '{多进程}'能'{利用多核资源}'并行计算, 但是进程也是有局限的.'{不要建立超过CPU总核数}'的进程,否则效率也不高(任务越多，任务切换的时间就越多)
    -> 程序系统大部分在做计算、逻辑判断、循环导致cpu占用率很高的情况，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力，称之为计算密集型(使用多进程)；频繁网络传输、读取硬盘及其他设备称之为IO密集型(使用多线程或协程)
    -> 计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写
    -> IO密集型任务执行期间，99%的时间都花在IO上，花在CPU上的时间很少，因此，用运行速度极快的C语言替换用Python这样运行速度极低的脚本语言，完全无法提升运行效率。对于IO密集型任务，最合适的语言就是开发效率最高（代码量最少）的语言，脚本语言是首选，C语言最差
    -> 当我们想实现多任务处理时,首先要想到使用'{multiprocessing}',但是如果觉着进程太笨重,那么就要考虑使用线程. 如果多任务处理中需要处理的太多了,可以考虑多进程,每个进程再采用多线程.如果还处理不要,就要使用轮询模式,比如使用poll event,twisted等方式.如果是GUI方式,则要通过事件机制,或者是消息机制处理,GUI使用单线程
    -> 多进程之间通信成本高，切换开销大
    -> 所以在python里线程不要盲目用,也不要滥用. 但是线程不安全是事实.如果仅仅是做几个后台任务,则可以考虑使用守护线程做.如果需要做一些危险操作,可能会崩溃的,就用子进程去做. 如果需要高度稳定性,同时并发数又不高的服务.则强烈建议用多进程的multiprocessing模块实现
    -> 在linux或者是unix里,进程的使用代价没有windows高.还是可以接受的
    -> 虽然Python多线程有缺陷，总被人说成是鸡肋，但也不是一无用处，它很适合用在IO密集型('{经常阻塞}')任务中。I/O密集型执行期间大部分是时间都用在I/O上，如数据库I/O，较少时间用在CPU计算上。因此该应用场景可以使用Python多线程，当一个任务阻塞在IO操作上时，我们可以立即切换执行其他线程上执行其他IO操作请求

    |线程退出
    -> 线程结束运算时就会退出。线程可以调用thread.exit()之类的退出函数，也可以使用退出进程的标准方法sys.exit(n)或raise SystemExit(1)。不可以直接杀掉Kill一个线程
    -> 主线程应该是一个好的管理者，它要了解每个子线程都要做些什么事，都需要什么数据和什么参数，以及在线程结束时，它们都提供了什么结果。这样就可以把各个子线程的结果组成一个有意义的最终结果
    -> 不建议使用thread模块。主要原因是当主线程退出的时候，其他所有子线程没有结束就退出了。而threading模块就能确保所有“重要的”子线程都退出后，进程才会结束

    |多进程
        > #多进程利用多核(4核CPU环境)
        > from multiprocessing import Process
        >
        > #dead loop
        > def loop():
        >     while 1: pass
        >
        > if __name__ == '__main__':
        >
        >     Process_list = []
        >     for i in range(3):
        >         p = Process(target=loop)
        >         p.start()
        >         Process_list.append(p)
        >
        >     #让主进程等待子进程执行完成
        >     for p in Process_list:
        >         p.join()
        >
        >     while 1: pass

    |多线程
        > import threading
        > import time
        >
        > local = threading.local() #隔离线程空间
        > #可以将ThreadLocal理解成一个dict,可以绑定不同变量.ThreadLocal用的最多的地方就是每一个线程处理一个HTTP请求，在Flask框架中利用的就是该原理，它使用的是基于Werkzeug的LocalStack
        >
        > def target():
        >     print 'current thread:%s' % threading.currentThread().name
        >     local.name = name
        >     print "%s in %s" % (local.name,threading.currentThread().name)
        >
        > print 'the curent threading  %s is running' % threading.current_thread().name
        > t1 = threading.Thread(target=target, args=('Bruce',))
        > t2 = threading.Thread(target=target, args=('Perseus',))
        > #为线程实例添加setDaemon(True)之后，如果不加join语句，那么当主线程结束之后，会杀死该线程.加上join,并设置等待时间t1.join(1)，就会等待线程一段时间再退出
        > t1.setDaemon(True) #其意义在于表示此线程不重要,默认情况下自动随主线程退出而退出
        > t2.setDaemon(True)
        > #所有的线程都创建之后，会一起调用start()函数启动线程，而不是创建一个启动一个
        > #join是阻塞当前线程，即在当前线程结束时，不会退出,会等到子线程结束，或者在给了timeout参数的时候，等到超时为止
        > #默认情况下，如果不加join语句，那么主线程会自然执行，但不会立即杀死子线程
        > t1.start()
        > t2.start()
        > t1.join()
        > t2.join()
        > print 'the curent threading  %s is ended' % threading.current_thread().name
        -----------------------------------------
        #线程锁
        > a = 3
        > lock = threading.Lock()
        > def target():
        >     print 'the curent threading  %s is running' % threading.current_thread().name
        >     time.sleep(4) #阻塞并挂起当前线程,系统切换到下一个线程运行
        >     global a
        >     lock.acquire() #锁住资源, 其他请求锁的线程阻塞等待
        >     try:
        >         a += 3
        >     finally:
        >         lock.release() #释放资源
        >     print 'the curent threading  %s is ended' % threading.current_thread().name
        >     print 'yes'
        -----------------------------------------
        #条件变量
        #线程A需要等某个条件成立才能继续往下执行，现在这个条件不成立，线程A就阻塞等待，而线程B在执行过程中使这个条件成立了，就唤醒线程A继续执行。在pthread库中通过条件变量（Condition Variable）来阻塞等待一个条件，或者唤醒等待这个条件的线程。

        #通俗的讲，生产者，消费者的模型。 condition很适合那种主动休眠，被动唤醒的场景。 condition使用难度要高于mutex，一不注意就会被死锁，SO一定要理解condition实现后再用

        #一个Condition实例的内部实际上维护了两个队列，一个是等待锁队列，mutex内部其实就是维护了一个队列。 另一个队列可以叫等待条件队列，在这队列中的节点都是由于（某些条件不满足）线程自身调用wait方法阻塞的线程，记住是自身阻塞。最重要的Condition方法是wait和 notify方法。另外condition还需要lock的支持， 如果你构造函数没有指定lock，condition会默认给你配一个rlock
        > condition=threading.Condition()
        > while 1:
        >    if condition.acquire():  #获取锁
        >        if len(task) > 1000:
        >            condition.wait() #条件不满足则一直阻塞等待
        > #                           1.加入到等待条件队列（注意这里不是等待锁的队列）
        > #                           2.释放锁
        > #                           3.阻塞自身线程
        > #                           ————条件满足, 被唤醒后执行————-
        > #                           4.尝试获取锁（这时线程已不在等待条件队列中，而是位于等待锁队列中，参见signal(notify)方法）
        > #                               4.1成功,从wait方法中返回，执行线程后面的代码
        > #                               4.2失败,阻塞自己（等待前一个节点释放锁时将它唤醒）
        > #注意：调用wait可以让当前线程休眠，等待其他线程的唤醒，也就是等待signal(notify)，这个过程是阻塞的。 当队列首线程被唤醒后，会继续执行wait方法后面的代码
        >        else:
        >            #doing task
        >            condition.notify() #唤醒wait队列的线程
        >                               #1.取出等待条件队列的首节点,放入等待锁队列的队尾
        >                               #2.唤醒节点对应的线程
        >        time.sleep(5)
        >        condition.release()

\异步IO(Eventloop + 消息队列)
    |Node
        |事件驱动 -> EventLoop是一个while(1)，用于等待和发送消息和事件。简单说，就是在程序中设置两个线程：一个负责程序本身的运行同时监听事件，称为"主线程"；另一个负责事件处理和回调操作，被称为"Eventloop线程"
            ReqWrap -> 主线程监听到事件发生, 封装回调函数和事件参数到请求对象, 随后将之推入'{线程池}'中等待多线程执行IO
                -> sys-cmd, webpage-opr, disk-IO, network-IO etc.

            IO-Threads -> 通知IOCP对象操作已经完成，并将线程归还给线程池.在这一过程中'{事件循环}'会调用GetQueuedCompletionStatus方法'{检查IOCP对象}'中是否有执行完的请求，有则将'{请求对象}'加入到IO'{观察者队列}'(消息队列)中，将其作为'{事件}'处理
                |IOCP(IO Completion Port) -> 一个线程同步对象，有点像信号量（semaphore）。一个IOCP对象和很多支持异步I/O调用的I/O对象相联系。线程有权阻塞IOCP对象，直到异步I/O调用完成
                    -> 高性能的I/O模型，是一种应用程序使用'{线程池}'处理异步I/O请求的机制

            |Eventloop -> 判断'{观察者队列}'中是否有事件需要处理, 有则取出事件; 事件有回调则执行回调函数
                -> 生产者/消费者模型
                > while(1){
                >   1.Get event from watchers
                >   2.Execute callback of event if exists
                >   3.Check IOCP and insert completed objs into watchers as events
                > }

                |Watcher -> 用来判断是否有事件需要处理(注册)。事件循环中有一到多个观察者，判断过程会向观察者询问是否有需要处理的事件
                    -> 类似于饭店的后厨与前台的关系。后厨每做完一轮菜，就会向前台经理询问是否还有要做的菜，如果有就继续做。服务员们相当于线程池, 前台经理就相当于观察者，他收到的顾客点单就是回调函数

    -> 使用Beanstalkd
    -> 解释AMQP，深入理解RabbitMQ，介绍RabbitMQ插件系统，RabbitMQ集群的故障转移方法等

    |Celery
    -> 介绍Celery的架构，运行起一个真实的应用，在Flask应用中使用Celery等功能
    -> 深入Celery，介绍Celery的依赖及独立用法、Worker管理、监控等高级功能
        -> Celery是一个由Python编写的简单、灵活、可靠的用来处理大量信息的分布式队列的管理系统,它同时提供操作和维护分布式系统所需的工具.专注于实时任务处理，支持任务调度
