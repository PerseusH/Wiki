进程fd -> 进程文件描述符
-> 大数据处理的效率在于良好的分布计算逻辑(并行计算),而不是什么语言.'{瓶颈在IO}',使用SSD硬盘解决

\IO
    |同步IO
    -> 在一个线程中,CPU执行代码的速度极快,一旦遇到IO操作,如读写文件,发送网络数据时,就需要等待IO操作完成,才能继续进行下一步操作:
    > do_some_code()
    > f = open('/path/to/file','r')
    > r = f.read() -> <== 线程停在此处等待IO操作结果
    > #IO操作完成后线程才能继续执行
    > do_some_code(r)

    |异步IO
    -> 当代码需要执行一个耗时的IO操作时,它只发出IO指令,并不等待IO结果,然后就去执行其他代码了.一段时间后,当IO返回结果时,再通知CPU进行处理
    -> 异步IO模型需要一个消息循环,在消息循环中,主线程不断重复"读取-处理消息"这一过程:(消息模型)
    > loop = get_event_loop() #事件队列
    > while True:
        > event = loop.get_event()
        > process_event(event) #发送消息

\Coroutine
    -> 事件驱动'{单线程}'的'{异步}'编程模型,'{没有切换开销}','{无需锁机制}'
    -> Python对协程的支持是通过'{generator}'实现的
    -> 在generator中,我们不但可以通过for循环来迭代,还可以不断调用next()函数获取由yield语句返回的下一个值或接收调用者发出的参数
    -> '{多进程+协程}',既充分'{利用多核}',又充分发挥'{协程的高效率}',可获得极高的性能

\Thread
    GIL -> Global Interpreter Lock,全局解释器锁,解释器执行代码时,任何Python线程执行前,必须'{先获得GIL锁}',然后,每执行100条字节码,解释器就自动释放GIL锁,让别的线程有机会执行.这个GIL全局锁实际上把所有线程的执行代码都给上了锁,所以,'{多线程}'在Python中只能交替执行,即使100个线程跑在100核CPU上,也只能用到1个核,在官方解释器上'{不能用多核}'实现真正的多线程
    -> python里的线程是操作系统的真实线程
    -> 多线程模式一旦线程数目过多,CPU切换线程的开销也会很大
    -> 多线程目前仅用于网络多线程采集,以及性能测试
    -> 其它的语言也有类似的情况,线程本身的特点导致线程的适用范围是受限的.只有CPU过剩,而其它的任务很慢,此时用线程才是有益的,可以很好平衡等待时间,提高并发性能
    -> 线程的问题主要是线程的安全稳定性.线程无法强制中止,同时线程与主进程共享内存,可能会影响主进程的内存管理
    -> 多线程致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃,因为所有线程共享进程的内存
    -> 那么怎么解决呢？通过我们用进程方式.子进程崩溃后,会完全的释放所有的内存和错误状态.所以进程更安全. 另外通过进程,python可以很好的绕过GIL,这个全局锁问题
    -> 但是进程也是有局限的.不要建立超过CPU总核数的进程,否则效率也不高
    -> 当我们想实现多任务处理时,首先要想到使用multiprocessing,但是如果觉着进程太笨重,那么就要考虑使用线程. 如果多任务处理中需要处理的太多了,可以考虑多进程,每个进程再采用多线程.如果还处理不要,就要使用轮询模式,比如使用poll event,twisted等方式.如果是GUI方式,则要通过事件机制,或者是消息机制处理,GUI使用单线程
    -> 所以在python里线程不要盲目用,也不要滥用. 但是线程不安全是事实.如果仅仅是做几个后台任务,则可以考虑使用守护线程做.如果需要做一些危险操作,可能会崩溃的,就用子进程去做. 如果需要高度稳定性,同时并发数又不高的服务.则强烈建议用多进程的multiprocessing模块实现
    -> 在linux或者是unix里,进程的使用代价没有windows高.还是可以接受的

\消息队列和Celery
    -> 使用Beanstalkd。
    -> 解释AMQP，深入理解RabbitMQ，介绍RabbitMQ插件系统，RabbitMQ集群的故障转移方法等。
    -> 介绍Celery的架构，运行起一个真实的应用，在Flask应用中使用Celery等功能。
    -> 深入Celery，介绍Celery的依赖及独立用法、Worker管理、监控等高级功能
        -> Celery是一个由Python编写的简单、灵活、可靠的用来处理大量信息的分布式队列的管理系统,它同时提供操作和维护分布式系统所需的工具.专注于实时任务处理，支持任务调度

\Spider
    |scrapy
