\分词
    |jieba -> Python中英文分词器
        |分词模式
            |精确模式 -> 试图将句子最精确地切开,适合文本分析
            |全模式 -> 把句子中所有的可以成词的词语都扫描出来,速度非常快,但是不能解决歧义
            |搜索引擎模式 -> 在精确模式的基础上对长词再次切分,提高召回率,适用于搜索引擎分词
        import jieba
        result = jieba.cut(txt[, cut_all=False]) #返回一个分词结果生成器. 精确模式(默认)
        result = jieba.cut(txt, cut_all=True) #全模式
        result = jieba.cut_for_search(txt) #搜索引擎模式

        |并行分词
            |原理 -> 将目标文本按行分隔后，把各行文本分配到多个 Python 进程并行分词，然后归并结果，从而获得分词速度的可观提升.基于python自带的multiprocessing模块,暂不支持Windows
            jieba.enable_parallel(4) # 开启并行分词模式，参数为并行进程数
            jieba.disable_parallel() # 关闭并行分词模式

\倒排索引
    -> 关键词: 文档列表(按词频, PageRank排序)
