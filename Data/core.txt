\Mysql
    1.谈谈mysql字符集和排序(校对)规则？
        |排序(校对)规则
        -> utf8_unicode_ci和utf8_general_ci对中、英文来说没有实质的差别
        -> utf8_general_ci校对'{速度快}',但准确度差
        -> utf8_unicode_ci准确度高,但校对'{速度慢}'
        -> 一般用'{utf8_general_ci}'

    2.varchar与char的区别是什么？大小限制？utf8字符集下varchar最多能存多少个字符？
        -> char有固定的长度,而varchar属于可变长的字符类型(需要1字节用来存储字段长度)
        -> varchar超过255字节需要2个字节标记字段长度
        -> char固定长度,在处理速度上比varchar快很多,但是较耗费存储空间.对于'{很短的,频繁改变的或定长的,在速度上有要求}'的字段可以使用char类型,反之可以用varchar
        -> 如果某char数据长度小于定长,MySQL就会在其右边用空格补足.在检索操作中会去掉填补的空格
        -> myisam建议使用'{char}'数据列代替可变长度的数据列
        -> memory目前都使用固定数据行存储,因此无论使用char|varchar列都没关系
        -> innodb建议使用'{varchar}'类型.因为它的数据行内部对char和varchar不加区分(所有数据行共用一个表头部分,这个部分存放着指向各有关数据列的指针),且char要占用更多空间
        -> varchar最多可存放65535个字节.char最多可存放255个字节,不同编码的最大可用字节数不同
        -> UTF-8中,一个英文字符等于一个字节,一个'{中文}'字符(含繁体)等于'{三个字节}',最大多存放65535/3=21845个字符.超过限制,varchar字段会被强行转为text类型,并产生warning

    3.primary key和unique的区别？
        |key -> 是数据库的物理结构,包含两层意义和作用
        1.约束(constraint)(约束和规范数据库的结构完整性)
        2.索引(index)(辅助查询用的)

        |primary key
        1.约束(唯一性,不能有NULL值,每个表都应有且只能有一个主键,自动定义UNIQUE)
        2.主键索引

        |unique key
        1.约束(唯一性,每个表可以有多个unique key)
        2.唯一索引

        -> Primary key的1个或多个列(联合主键)必须为NOT NULL,如果列为NULL,在增加PRIMARY KEY时,列自动更改为NOT NULL.而UNIQUE KEY对列没有此要求

    4.外键有什么用,是否该用外键？外键一定需要索引吗？
        |作用 -> 表的主从关联
        -> 大用户量,高并发场景下不要使用;传统小规模软件和内部小规模项目可以用,因为开发成本低
        -> '{父表}'关联字段必须'{显式创建索引}'(单字段索引或位于最左位置的组合索引);'{子表}'外键字段也是索引字段(如果不是索引字段建立外键关系的时候MySQL会'{隐式地为该字段创建一个普通索引}').即外键相关字段最后'{一定是索引字段}'

        |性能问题
        1.数据库需要维护外键的内部管理.等于把数据的一致性事务实现,全部交给数据库服务器完成
        2.涉及外键字段的增,删,更新操作之后,需要触发相关操作去检查,需要消耗资源
        3.外键因为需要请求对其他表内部加锁而容易出现死锁情况

    5.myisam与innodb的区别？innodb的两阶段锁定协议是什么情况？
        -> myisam不支持事务,不会表扫描;innodb支持事务,会表扫描

        -> 因为有大量的并发访问,为了预防死锁,一般应用中使用一次封锁法,就是在方法的开始阶段,已经'{预先知道}'会用到哪些数据,然后全部锁住,在方法运行之后,再全部解锁.一次锁可以有效避免循环死锁,但在数据库中却不适用,因为在事务开始阶段,数据库'{并不知道会用到哪些数据}'

        |innodb两段锁定协议 -> 将'{事务}'分成加锁和解锁两个阶段
        1.加锁阶段 -> 在对任何数据进行'{读操作之前}'要申请并获得S锁('{共享锁}',其它事务可以继续加共享锁,但不能加排它锁),在进行'{写操作之前}'要申请并获得X锁('{排它锁}',其它事务不能再获得任何锁).加锁不成功,则事务进入等待状态,直到'{加锁成功才继续执行}'.
        2.解锁阶段 -> 当事务释放了一个封锁以后,事务进入解锁阶段,在该阶段只能进行解锁操作不能再进行加锁操作.锁在执行'{COMMIT和ROLLBAK的时候才会释放}',且所有锁在同一时刻被释放
        -> 这种方式虽然无法避免死锁,但可以保证事务的'{并发}'调度'{串行化}'(串行化很重要,尤其是在数据恢复和备份的时候)

    6.索引有什么用,大致原理是什么？设计索引有什么注意点？
        |索引作用 -> 快速定位数据,往往以索引文件的形式存储的磁盘上

        |索引原理
        1.B-Tree
        2.B+Tree

        |索引设计要点
        1.尽量小的数据类型 -> 越小的数据类型在磁盘、内存和CPU缓存中占用更少的空间,处理起来更快
        2.尽量简单的数据类型 -> 整型数据比起字符型开销更小,字符串比较复杂
        -> 应该用内置的日期和时间类型,而不是用字符串来存储时间;用整型而不是字符型存储IP地址
        3.尽量避免NULL -> 应该指定列为NOT NULL,除非你想存储NULL
        -> 含有空值的列很难进行查询优化,因为它们使得索引、索引的统计信息以及比较运算更加复杂.
        -> 用0、空字符串或者特殊值代替NULL

\Redis
    |原理
    1.Redis内部使用一个'{redisObject}'对象来表示所有的key和value
    2.Redis的Hash实际是内部存储的'{Value}'为一个HashMap,并提供了直接存取这个Map成员的接口,解决了重复存储数据的问题
    3.Redis的list是每个子元素都是String类型的'{双向链表}',可以通过push和pop操作从列表的头部或者尾部添加或者删除元素,这样List'{既可以作为栈,也可以作为队列}'
    4.Redis的Set是String类型的无序hashtable,概念和数学中个的集合基本类似,可以交集(redis.sinter),并集(redis.sunion),差集(redis.sdiff)等等,set中的元素是没有顺序的,可以'{自动排重}'
    5.基于程序的'{局部性访问原理}',CPU访问'{内存}'而不是磁盘,这大大提升了运行的速度

    1.什么场景用redis,为什么mysql不适合？
        1.会话缓存(Session Cache)-> Redis优势在于提供'{持久化}'
        2.全页缓存(FPC)-> 有磁盘的持久化,即使重启Redis实例,用户也不会看到页面加载速度的下降
        3.消息队列 -> 提供list和set操作,这使得Redis能作为一个很好的消息队列平台来使用
        4.排行榜/计数器 -> Redis在内存中对'{数字增减}'的操作实现的非常好.集合(Set)和有序集合(Sorted Set)也使得我们在执行这些操作的时候变的非常简单
        5.'{数据变化快}'的应用 -> 消息队列, 排行榜, 计数器, 时间线, 关注列表, 股票交易

        -> mysql的'{磁盘IO}'操作,数据排序,表关联,锁机制
        -> 一般来说,写入数据是直接到mysql,读取的是redis. mysql->redis同步数据

    2.谈谈redis的事务？用事务模拟原子+1操作？原子操作还有其它解决方案吗？
        > watch intA
        > intA_tmp = intA + 1
        > multi
        > set intA intA_tmp
        > exec

    3. redis相比memcached有哪些优势？
        1.memcached所有的值均是简单的字符串，redis支持'{更丰富的数据类型}'
        2.redis的速度比memcached'{快}'很多
        3.redis可以'{持久化}'其数据
        4.redis单个value的最大限制是1GB，memcached只能保存1MB的数据

    4.redis内存满了会怎么样？
        1.主库宕机('{主从切换代价大}')
        -> redis在主库挂掉以后,从库升级为新的主库.那么'{切换主库}'以后,所有的从库都需要跟新主做一次全同步,代价非常大
        2.扩容('{扩容时间长}')
        -> 很多时候会出现流量的突发性增长,通常在找到原因之前我们的应急做法就是扩容.根据经验,一个20G的redis扩容一个从库需要将近20分钟
        3.网络不好导致从库重做最终引发雪崩效应('{主从同步代价大}')
        -> 该场景的最大问题是主库与从库的同步中断,而此时很可能从库仍然在接受写入请求,那么一旦中断时间过长同步缓冲区就很可能被复写.此时从库上一次的同步位置已丢失,在网络恢复后虽然主库没有发生变化但由于从库的同步位置丢失了'{从库必须进行重做}'.如果此时主库内存体积过大那么从库重做速度就会很慢,而发送到从库的读请求就会受到严重影响,同时由于传输的rdb文件的体积过大,主库的网卡在相当长的一段时间内都会受到严重影响
        4.内存越大,触发持久化的操作'{阻塞主线程的时间越长}'
        -> Redis是单线程的内存数据库,在redis需要执行耗时的操作时,会fork一个新进程来做,比如bgsave,bgrewriteaof. Fork新进程时,虽然可共享的数据内容不需要复制,但会复制之前进程空间的内存页表,这个复制是主线程来做的,会阻塞所有的读写操作,并且随着内存使用量越大耗时越长.例如:内存20G的redis,bgsave复制内存页表耗时约为750ms,redis主线程也会因为它阻塞750ms
        5.'{内存太贵}'

        |解决办法 -> 极力减少内存的使用
        1.设置'{过期时间}' -> 对具有时效性的key设置过期时间,redis自身有过期key清理策略
        2.不存放垃圾到redis中,及时'{清理无用数据}'
        -> 例如一个redis承载了3个业务的数据,若有两个业务下线,就及时清理这两个业务的相关数据
        3.'{数据压缩}' -> 例如一些长文本形式的数据,压缩能够大幅度降低内存占用
        4.关注内存增长并'{定位大容量key}'
        -> 分析redis实例中哪些key比较大从而快速定位异常key(非预期增长的key,往往是问题之源)
        5.'{pika}'
        -> 360DBA和基础架构组联合开发的'{类redis存储系统}',使用Redis协议,兼容redis绝大多数命令(String,Hash,List,ZSet,Set),'{不需要修改任何代码}',就可以将服务迁移至pika
        -> 如果实在不想搞的那么累,那就把业务迁移到新开源的pika上面,这样就不用太关注内存了,redis内存太大引发的问题,那也都不是问题了
        -> pika使用的是'{多线程}'模型,使用多个工作线程来进行读写操作,线程分为11种
        '{容量大}' -> Pika没有Redis的内存限制,最大使用空间等于磁盘空间的大小
        '{加载db速度快}' -> Pika在写入的时候,数据是落盘的,所以即使节点挂了,不需要rdb或者aof,pika重启不用重新加载数据到内存而是直接使用已经持久化在磁盘上的数据,不需要任何数据回放操作(除去少量rocksdb自身的recover),这大大降低了重启成本
        '{备份速度快}' -> Pika备份的速度大致等同于cp的速度(拷贝数据文件后还有一个快照的恢复过程,会花费一些时间),目前已经开发完更快更省空间的秒级备份,即将投入使用,这样在对于百G大库的备份是快捷的,更快的备份速度更好的解决了主从的全同步问题
        -> 存储引擎是rocksdb,性能比Redis低一些,一般使用SSD盘来存放数据
