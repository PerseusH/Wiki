\锁
    |悲观锁(Pessimistic Lock) -> 先获取锁，再进行业务操作
    -> 顾名思义,就是很悲观,'每次'去拿数据的时候'都认为别人会修改',所以每次在拿数据的时候都会上锁,这样别人想拿这个数据就会block直到它拿到锁.传统的关系型数据库里边就用到了很多这种锁机制,比如'行锁,表锁,读锁,写锁'等,都是在做操作之前先上锁

    |乐观锁(Optimistic Lock) -> 先进行业务操作，不到万不得已不去拿锁
    -> 顾名思义,就是很乐观,'每次'去拿数据的时候'都认为别人不会修改',所以不会上锁,但是在更新的时候会判断一下在此期间别人有没有去更新这个数据,可以使用版本号比较等机制.乐观锁适用于多读的应用类型,这样可以提高吞吐量,像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁
    -> 版本号比较机制是在读数据的时候，将读到的数据的版本号一起读出来，当对数据的操作结束后，准备写数据的时候，再进行一次数据版本号的比较，若版本号没有变化，即认为数据是一致的，没有更改，可以直接写入，若版本号有变化，则认为数据被更新，不能写入，防止脏写
    > SELECT data AS old_data, version AS old_version FROM …;
    > 根据获取的数据进行业务操作，得到new_data和new_version
    > UPDATE SET data = new_data, version = new_version WHERE version=old_version
    > if (updated row > 0)
    >     // 乐观锁获取成功，操作完成
    >  else
    >     // 乐观锁获取失败，回滚并重试
    >
    -> 乐观锁是否在事务中其实都是无所谓的，其底层机制是这样：在数据库内部update同一行的时候是不允许并发的，即数据库每次执行一条update语句时会获取被update行的写锁，直到这一行被成功更新后才释放。因此在业务操作进行前获取需要锁的数据的当前版本号，然后实际更新数据时再次对比版本号确认与之前获取的相同，并更新版本号，即可确认这之间没有发生并发的修改。如果更新失败即可认为老版本的数据已经被并发修改掉而不存在了，此时认为获取锁失败，需要回滚整个业务操作并可根据需要重试整个过程

    -> 两种锁各有优缺点,不可认为一种好于另一种.'乐观锁'适用于'写比较少'的情况下,即冲突很少发生的时候,这样可以省去了锁的开销,加大了系统的整个吞吐量.但如果'经常产生冲突',上层应用会不断的进行retry,这样反倒是降低了性能,所以这种情况下用'悲观锁'就比较合适

    |innodb两段锁定协议(2PL：Two-Phase Locking) -> 将事务分成加锁和解锁两个阶段
        1.加锁阶段 -> 在对任何数据进行'读操作之前'要申请并获得S锁,在进行'写操作之前'要申请并获得X锁.加锁不成功,则事务进入等待状态,直到'加锁成功才继续执行'.
        2.解锁阶段 -> 当事务释放了一个封锁以后,事务进入解锁阶段,在该阶段只能进行解锁操作不能再进行加锁操作.锁在执行'COMMIT和ROLLBAK的时候才会释放',且所有锁在同一时刻被释放
        -> 这种方式虽然无法避免死锁,但可以保证事务的'并发'调度'串行化'(串行化很重要,尤其是在数据恢复和备份的时候)

    |行锁(Record Lock) ->  InnoDB行锁是通过给索引上的'索引项加锁'来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。 InnoDB这种行锁实现特点意味着：只有'通过索引检索数据'，InnoDB才使用行级锁; '没有索引的情况下，InnoDB只能使用表锁'！在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能. 不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁
        |共享锁(S锁,读锁) -> 读锁相互不阻塞, 阻塞所有其他写锁.其他事务'可读不可写'加锁对象
        -> 若事务T对对象A加上S锁,则T'可以读A但不能修改A',其他事务只能再对A加S锁,而'不能加X锁',直到T释放A上的S锁
            SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE

        |排他锁(X锁,写锁) -> 会阻塞其他的写锁和读锁.其他事务'不可读写'加锁对象
        -> 若事务T对对象A加上X锁,则T'可以读A也能修改A',其他事务不能再对A加任何锁,直到T释放A上的锁
        -> Mysql InnoDB 排他锁
        -> 用法: select … for update;
            > begin;
            > select * from goods where id = 1 for update;
            > update goods set stock = stock - 1 where id = 1;
            > commit;
        -> 在高并发的时候，这些业务逻辑受到 CPU 及网络等资源的限制可能会被拖慢，业务逻辑处理慢倒没什么，可怕的是数据库被拖慢,反过来又影响这些业务逻辑,形成一个滚雪球的效应,直至系统故障(假死)
        -> 共享锁主要用来'确认某行记录是否存在，并确保没有人对这个记录进行UPDATE或DELETE操作'。但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用SELECT... FOR UPDATE方式获得排他锁

        1.对于'UPDATE、DELETE和INSERT'语句，InnoDB会自动给涉及数据集加排他锁
        2.对于普通'SELECT'语句，InnoDB不会加任何锁
        3.'事务'可以显式给记录集加共享锁(LOCK IN SHARE MODE)或排他锁(for update)

    |表锁 -> 对于InnoDB表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们之所以选择InnoDB表的理由。但在个别特殊事务中，也可以考虑使用表级锁
        1.事务需要'更新大部分或全部数据'，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度
        2.'事务涉及多个表'，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销
        当然应用中这两种事务不能太多，否则就应该考虑使用MyISAM表了

        -> 在InnoDB下，使用表锁要注意以下两点
            1.使用LOCK TABLES虽然可以给InnoDB加表级锁，但必须说明的是，表锁不是由InnoDB存储引擎层管理的，而是由其上一层: MySQL Server负责的，仅当autocommit=0、innodb_table_locks=1（默认设置）时，InnoDB层才能知道MySQL加的表锁，MySQL Server也才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁；否则，InnoDB将无法自动检测并处理这种死锁。有关死锁，下一小节还会继续讨论。
            2.在用 LOCK TABLES对InnoDB表加锁时要注意，要将AUTOCOMMIT设为0，否则MySQL不会给表加锁；事务结束前，不要用UNLOCK TABLES释放表锁，因为UNLOCK TABLES会隐含地提交事务；COMMIT或ROLLBACK并不能释放用LOCK TABLES加的表级锁，必'须用UNLOCK TABLES释放表锁'。正确的方式见如下语句:
                SET AUTOCOMMIT=0;
                LOCK TABLES t1 WRITE, t2 READ, ...;
                [do something with tables t1 and t2 here];
                COMMIT;
                UNLOCK TABLES;

    |间隙锁（GAP Lock）-> 锁定索引记录间隙，确保索引记录的间隙不变。间隙锁是针对事务隔离级别为可重复读或以上级别而设的。当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于'键值在条件范围内但并不存在的'记录，叫做“间隙（GAP)”，InnoDB也会对间隙加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。InnoDB除了通过范围条件加锁时使用间隙锁外，如果使用相等条件请求给一个不存在的记录加锁，InnoDB也会使用间隙锁

    |Next-Key锁 -> 行锁和间隙锁组合起来就叫Next-Key Lock

    |策略 -> MyISAM和MEMORY只支持表锁;BDB采用页锁,也支持表锁;InnoDB支持行锁和表锁,默认采用行锁
        |表锁 -> 开销小,加锁快;不会出现死锁;锁定粒度大,发生锁冲突的概率最高,并发度最低
        |行锁 -> 开销大,加锁慢;会出现死锁;锁定粒度最小,发生锁冲突的概率最低,并发度也最高
        |页锁 -> 开销、加锁时间和锁定粒度界于表锁和行锁之间;会出现死锁;并发度一般

    |意向锁 -> 为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB还有两种内部使用的意向锁（Intention Locks），这两种'意向锁都是表锁'。'意向锁是InnoDB自动加的'，不需用户干预
      |意向共享锁(IS) -> 事务打算给数据行加行共享锁，事务在给数据行加共享锁前必须先取得该表的IS锁
      |意向排他锁(IX) -> 事务打算给数据行加行排他锁，事务在给数据行加排他锁前必须先取得该表的IX锁

\事务
    |ACID
    A(Atomicity,原子性)
    -> 事务开始后所有操作,要么全部做完,要么全部不做,不可能停滞在中间环节.事务执行过程中出错,会回滚到事务开始前的状态,所有的操作就像没有发生一样
    C(Consistency,一致性)
    -> 事务开始前和结束后,数据库的完整性约束没有被破坏.比如A向B转账,不可能A扣了钱,B却没收到
    I(Isolation,隔离性)
    -> 同一时间,只允许一个事务请求同一数据,不同的事务之间彼此没有任何干扰.比如A正在从一张银行卡中取钱,在A取钱的过程结束前,B不能向这张卡转账
    D(Durability,持久性)
    -> 事务完成后,事务对数据库的所有更新将被保存到数据库,不能回滚
    -> '原子性'是事务隔离的'基础',隔离性和持久性是手段,'最终目的'是保持数据的'一致性'

    |事务隔离级别
        1.Read_Uncommitted(读取未提交内容)
        -> 在该隔离级别,所有事务都可以看到其他未提交事务的执行结果.本隔离级别很少用于实际应用,因为它的性能也不比其他级别好多少.读取未提交的数据,也被称之为脏读(Dirty Read)
        2.Read_Committed(读取提交内容)
        -> 这是'大多数数据库系统'的'默认隔离级别'(但不是MySQL默认的).它满足了'隔离'的简单定义:'一个事务只能看见已提交事务所做的改变'.这种隔离级别也支持所谓的不可重复读(Nonrepeatable Read),因为同一事务的其他实例在该实例处理期间可能有新的commit,所以同一select可能返回不同结果
        3.Repeatable_Read(RR, 可重读)
        -> 这是'MySQL的默认事务隔离级别',它确保同一事务的多个实例在并发读取数据时,会看到同样的数据行.不过理论上,这会导致另一个棘手的问题:幻读(Phantom Read).简单的说,幻读指当用户读取某一范围的数据行时,另一个事务又在该范围内插入了新行,当用户再读取该范围的数据行时,会发现有新的“幻影” 行.InnoDB和Falcon存储引擎通过多版本并发控制(MVCC,Multiversion Concurrency Control)机制解决了该问题
        4.Serializable(可串行化)
        -> 这是最高的隔离级别,它通过'强制事务排序',使之不可能相互冲突,从而'解决幻读问题'.简言之,它是在每个读的数据行上加上共享锁.在这个级别,可能导致大量的超时现象和锁竞争

    |事务的并发问题
        1.'脏读' -> 事务A读取了事务B更新的数据,若B回滚,那么A读取的数据就是脏数据('绝对拒绝')
        2.'不可重复读' -> 事务A多次读取同一据,事务B在事务A多次读取的过程中,对数据作了更新并提交,导致事务A多次读取同一数据时,结果不一致. 侧重于'更新'. 解决方法是'加行锁'
        3.'幻读' -> 系统管理员A将数据库中所有学生的成绩从具体分数改为ABCDE等级,但是系统管理员B就在这个时候插入了一条具体分数的记录,当系统管理员A改结束后发现还有一条记录没有改过来,就好像发生了幻觉一样,这就叫幻读. 侧重于'插入或删除'. 解决方法是'加GAP锁'

    事务隔离级别	               脏读	不可重复读	幻读
    读未提交(read-uncommitted)  是	   是	    是
    不可重复读(read-committed)  否	  是        是
    可重复读(repeatable-read)   否	   否        是
    串行化(serializable)	     否	    否        否
